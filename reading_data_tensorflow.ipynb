{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data with Tensorflow\n",
    "\n",
    "In this notebook I cover how to prepare a queued & batched dataset to feed into your tensorflow machine learning model. The data is read from a google-cloud-storage bucket, and is optimized for cloud training with google's ml-engine. All functions work for local paths, or for paths directed to a GCS bucket and uses only Numpy & Tensorflow.\n",
    "\n",
    "Data used here is the <a href = \"http://yann.lecun.com/exdb/mnist/\"> MNIST dataset </a> which contains handwritten digits from <em>0</em> to <em>9</em>.\n",
    "\n",
    "Data is given in 4 bianary files: training data, training labels and test data, test labels.\n",
    "\n",
    "\n",
    "All we need to know about the dataset:\n",
    "\n",
    "        Training and test label data starts at byte 8. Each label is one byte, uint8, value 0-9 \n",
    "    \n",
    "        Training and test image data starts at byte 16. Label is ordered by row, each image is [28,28] = 784 bytes, uint8, value 0-255 (these are grayscale images).\n",
    "    \n",
    "\n",
    "\n",
    "For more information about the datafiles see the <a href = \"http://yann.lecun.com/exdb/mnist/\">MNIST website.</a>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, we need to know which files we want to read. Assuming all our data is in one directory we can list the files using <em> tf.gfile.ListDirectory() </em>. I hosted the MNIST data in a GCS bucket so you can directly run this notebook, or you can download the MNIST data youself and run locally. Remember tf.gfile works for local directories as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files to read:  ['t10k-images-idx3-ubyte', 't10k-labels-idx1-ubyte', 'train-images-idx3-ubyte', 'train-labels-idx1-ubyte']\n"
     ]
    }
   ],
   "source": [
    "BUCKET = \"gs://organicml-reading-data\"\n",
    "data_prefix = BUCKET + \"/data\"\n",
    "file_list = tf.gfile.ListDirectory(data_prefix)\n",
    "print(\"Files to read: \",file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's read our data!\n",
    "\n",
    "Setting up the tensorflow data pipeline consists of the following steps:\n",
    "\n",
    "        First we prepare a list of files to read (already done!)\n",
    "    \n",
    "        Next we queue the file list for tensorflow to read,\n",
    "    \n",
    "        Third, initialize a reader and read our filename queue\n",
    "    \n",
    "        Following reading, we decode our data into the correct format (plus any addictional preprocessing steps desired).\n",
    "\n",
    "        Lastly we batch our data. Now it is ready to be passed to our model!\n",
    " \n",
    "\n",
    "Because our images and labels are contained in seperate files, we will use two queues, readers and decoders and then batch images and labels together.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split image and label files.\n",
    "image_files = [os.path.join(data_prefix,i) for i in file_list if \"image\" in i]\n",
    "label_files = [os.path.join(data_prefix,i) for i in file_list if \"label\" in i]\n",
    "\n",
    "# Create queue.\n",
    "image_queue = tf.train.string_input_producer(image_files,name = \"image_queue\")\n",
    "label_queue = tf.train.string_input_producer(label_files,name = \"label_queue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating our filename queue, we are ready to read. We use a tensorflow <em>reader</em> to pull our data from files, then a <em>decoder</em> to decode the data into a suitable data type. We can keep track of the number of files we have read with the reader's <em>num_records_produced()</em> attribute\n",
    "\n",
    "Before reading we need to recall some details:\n",
    "\n",
    "    The size of the header data in the file (8 bytes for labels & 16 for images).\n",
    "\n",
    "    The data size and type (28 x 28 pixel images, all data is unsigned 8 bit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = [28,28,1]# The size 1 dimension is included for generalization to color images.\n",
    "image_start_byte = 16 \n",
    "label_start_byte = 8\n",
    "\n",
    "height = IMAGE_SHAPE[0]\n",
    "width = IMAGE_SHAPE[1]\n",
    "depth = IMAGE_SHAPE[2]\n",
    "\n",
    "image_bytes = height * width * depth \n",
    "label_bytes = 1  \n",
    "\n",
    "# Create reader. \n",
    "image_reader = tf.FixedLengthRecordReader(record_bytes = image_bytes, \n",
    "                                        header_bytes = image_start_byte)\n",
    "\n",
    "label_reader = tf.FixedLengthRecordReader(record_bytes = label_bytes, \n",
    "                                          header_bytes = label_start_byte)\n",
    "\n",
    "\n",
    "# Read! Key is the location of file read. Value is the data returned.\n",
    "image_key, image_value = image_reader.read(image_queue)\n",
    "label_key, label_value = label_reader.read(label_queue)\n",
    "\n",
    "# Convert from a string to a vector of uint8 that is record_bytes long.\n",
    "decoded_image = tf.decode_raw(image_value, tf.uint8)\n",
    "decoded_label = tf.decode_raw(label_value, tf.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data has been read from the file and is almost ready to be batched. We obtain single image and label pairs by taking slices of decoded_bytes.\n",
    "\n",
    "Before batching, tensorflow requires shapes to be fully defined.\n",
    "\n",
    "Labels are shaped to <em>[1]</em>\n",
    "Our images need to be reshaped to <em>[height,width,depth]</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_label = tf.reshape(\n",
    "    tf.strided_slice(decoded_label,[0],[label_bytes]),\n",
    "    [1])\n",
    "\n",
    "uint8_img = tf.reshape(\n",
    "    tf.strided_slice(decoded_image, [0],[image_bytes]),\n",
    "    [height, width, depth])\n",
    "\n",
    "# Cast image to desired dtype \n",
    "training_image = tf.cast(uint8_img,tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we have left to do is make our batches. Nearly all deep learning models accept data in batches to improve speed and prevent overfitting. For large datasets we can use multiple threads to prepare our data in parrallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_preprocess_threads = 2\n",
    "min_queue_examples = 1\n",
    "\n",
    "image_batch, label_batch = tf.train.batch(\n",
    "    [training_image, training_label],\n",
    "    batch_size=batch_size,\n",
    "    num_threads=num_preprocess_threads,\n",
    "    capacity=min_queue_examples + 16 * batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batches are of shape <em>[batch_size,height,width,depth]</em> and ready to be fed into a model. Each time we call image and label batch in a session we have one batch returned. To fetch one batch of training data, we can run the session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    BATCH = [image_batch,label_batch] \n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    coord = tf.train.Coordinator() \n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    B = sess.run(BATCH)\n",
    "    #x_train,y_train = sess.run([image_batch,label_batch])\n",
    "            \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 28, 28, 1)\n",
      "\n",
      "[[5]\n",
      " [0]\n",
      " [4]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "img = B[0]\n",
    "label = B[1]\n",
    "print(img.shape)\n",
    "print()\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our first batch! We can view the images and labels to make sure they match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "matplotlib.rc('animation', html='html5')\n",
    "\n",
    "\n",
    "def plot_image_batch(image,label):\n",
    "    shape = image.shape\n",
    "    num_steps = shape[0]\n",
    "    fig = plt.figure(figsize = (5,5))\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    def animate(i):\n",
    "        im = ax.imshow(image[i],cmap=plt.get_cmap(\"gray\"))\n",
    "        return im,\n",
    "    return matplotlib.animation.FuncAnimation(fig, animate, frames=range(0,num_steps), interval=2000, blit=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [5], [0], [4], [1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video width=\"360\" height=\"360\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAAgqm1kYXQAAAKtBgX//6ncRem9\n",
       "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTQ4IHIyNzk1IGFhYTlhYTggLSBILjI2NC9NUEVHLTQg\n",
       "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE3IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
       "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
       "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
       "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
       "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9NiBsb29r\n",
       "YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n",
       "ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n",
       "bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n",
       "aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MSBzY2VuZWN1dD00MCBpbnRyYV9yZWZyZXNo\n",
       "PTAgcmNfbG9va2FoZWFkPTQwIHJjPWNyZiBtYnRyZWU9MSBjcmY9MjMuMCBxY29tcD0wLjYwIHFw\n",
       "bWluPTAgcXBtYXg9NjkgcXBzdGVwPTQgaXBfcmF0aW89MS40MCBhcT0xOjEuMDAAgAAADUdliIQA\n",
       "F//+99S3zLLtU2+2C6j3op4mX0N1JQGblsTtOoAAACuVKy89g9rMS67AAhpX/+PhIeIAiQXUoa5m\n",
       "jD6aVSwYQLBaa36hLswl8M0foJ0w3hTt1qkmgHDS3QxdMthK99iECsnMJ//Xo9uEzHKLSdV+eRWk\n",
       "g98DKNsmfrn6S/cz9vajLy9bav4dgxUjVM8mmv63qhN9tRps/W6o5m0D8mJOBx7iR04b6yCGlW9W\n",
       "Efe6G9hd6t7Lol0v92xCEAABnwljJ/DDJWHmWE/AEUP0O0dwC9dBmrGqISq5OZz1z4DE1Ndr11hO\n",
       "kau8K39S9gdj2Nnebn9dJ22VgNRikKqPc8f8f01X0GN+hdoFSH6gsiJ29bqpYpOK8Bdtloz9xobI\n",
       "UE2WGzyMGG1rRQ/1mL8UMl3h7+d+EDE61brLZZYnKgRX5QyTHQ3rYRgc7tKfrISeBj4GfQ6f8e0e\n",
       "JWxGlIHLOaSbf///L3/BmP4SyxcfXcWX5PGOQ0YjRZ3CPAxlFIpf26rVtkqKAxlIkCbtwOAFE/Rn\n",
       "YzAVZQ9BcRtkfOTEGT3AsHIj+k8XRgZtO7/75HgupTm+yGfPexvhkv/CN8PPv6ML2bc2xI++GKsg\n",
       "VP5g47Y9ykgeMfBDl48tiQu8j+8bWQfYuvzrshdLzwBgJwaz/CKzT6BIl8VH2bheWvQr4r2wda/Q\n",
       "/fhXAVbQtJOr04Y/DbpibxDlBYSgkVssebGU//LYrb+8fAJ1udqCMs5NuGZoHLqKDPqaTOri58gr\n",
       "HcbjGxmGTnlS2B/6T+P+cjrHZHqg7U5phbY2TwuvMLQbqV4b4wJ3bvM6B8MfpoleTthAmXsxcr0Z\n",
       "Y0fVPlf2tRX1xEaA87ZWn0PbDuV/trLJWrluK2lb/NRnT3M69d52+B5TtfKr77iz1xsHC/ed5m53\n",
       "ZvOBRLbj8A4vR9xKhZ8oiLLlhfxQnNetlsztjFQ2o0596hx8FCuF/g8AClazlQVo5ThkCCj+iXe5\n",
       "bilA9MoskqfC4c/cSRHisdGItdUFWv7jnVEzGP0Odpoxdv7iLz9zZDc64yWfzbXLohpDlgAtNHdg\n",
       "d9uN86Pufj57MFuQ2pmzG21+mg7DlnuCoVcBvYUzsUZBRnri+9Vw0XXYA41+Lt9FelVJb+R4vP12\n",
       "71RGP//pRqGy2mkTAvuNG8XL7nkrIBTW+pfcuezEzlsknh1N1FwBec4D1zwRKBgDuVpdbcXxM93c\n",
       "BXptLXf/Fsifl5S9H2uiu1pqQUfBdROSpHxQkFR992tnsvbv8Zxi/LcFDW0XNMg8sEp6ZFxSZZXg\n",
       "NEdsaraATg1gfL6TGxFCsNsvPxDOt04tvs4Dt2O3zg4Xwpn8eWWLVyf7Ol5rz0POXcJEZQcgN9xf\n",
       "94/NldBPNbLZi6NhWH8IjZxejvmD5PWbBJ1x0Ji1zDnI0PpyxPZq7Tax6L/Vzxshzs5mo+qT4VEv\n",
       "bNn7MqlUnnd22ONu2hP9urjDmx04EbwK0nqGSwgeiSpURYmLNCBHyBCTN9IL30BbOHqGBXOBzVEC\n",
       "UeRyg5uX8qlCng+RMFrqAEXY958XOZvK00ecxOBmk2qsIKx451aGCWSQQ0TZx6KoivMCgC52WfIG\n",
       "1fuJ15y7kwl7lWML4iT+1OFjhv0eiw84l8Wog9cLGJudU8+dCenEvYeaUU+xRtmaVNgTW1s+c1FP\n",
       "5G8xDVdl9y/FDfDcQ7XS4Md8fkNKM4G69wZsSDcSeAjvlSMzdfwrH5grM/4nzmG+1bfSlJ4PxNPC\n",
       "yPxMHzE9CbWqQfvgtPKF3rNdsbfu+OXvAWIJTdE99urQuBUGdaDOnFfgftHIvyQnZ2heMPXTu7t8\n",
       "nwyOePZhhsUeNm6ia3pw4y2uuMFXQ/JBzSnG3zaLfJQKZVr7clZfdYlV1/RYKB8xn6pTPYmNC72k\n",
       "gUjoivMzLphJ7JrKnj9BCR9k3GfZXmFTr+68gCKoHjzawPzx3zfSSbpk9CUq5sPNt4gQaOq+VUvn\n",
       "cpLuQSNxkURt8wX4tZtv9JiUU4/JHLLYfgQwLg0xhv5VDaDa3fi7t+djx/dpLNz+6L2usQZnIYn+\n",
       "7s9bsQqXXwQTCeWxCg6khcbuDeNA4dTy9H5tNhUpn/gPr9ZCWBvLlrp2UUmSsYZU2T+5bUGiyRmy\n",
       "qmaAtq9JV64vdjqBit6NmGzRxOtdLbQ56ky5j8tL5LSJyzEsUup8akz2lqDZGa0/VgvZkFbmkVfG\n",
       "RxmOBOt/sWRMbPlEqxIkMrm8Tq6/DJYBKITekcrmQzsltNHNwddm0UCeZ6M5QJ/TD3YByA13ETW8\n",
       "SV/ebFfKvPQyrgzvhglXMmaTJtrTyMBJ2D7IHaicjMFn2JsqdkqpNigp3J/q1coZqnjECNbFdeoh\n",
       "8LEh1uHTdHJNeRvX9c8p7QMaZrSwoEl7+IRSmrf0TEdJg+xpCALwKbNJcJm+BmdJpg2tkbXEAf8n\n",
       "2y9dxznSVprsJ+zTMi/hGJcUQ38pCK1m7gqoy2nLYHTB77WL/3i1XQclqonwzmtuhC+KTppLdxQt\n",
       "M/fI/0xWVar4k0YgnbDw1owBKCpn8GKnZUaXyJcsUFcX34VGSNJL30yzqBNpgrBDKkq7pWyx+Yhb\n",
       "fR05t/sGNnDEAy7SJJVTdAal4wizu2dl6MLyuf2xJ5opGueTpkUK3iGSJfmIlefq9F1il8VAJo5S\n",
       "eNTnMfL1K+sQnjvuw0cb0ShxwZzR+kIo7O4A3s5+FPIVsJQ5UDXEsQv6xqHiQYUrx6ISn/90xjh4\n",
       "UekfBfExHKRNBAIrG2SwLk1tSb7UH+8EbjmQ66hRpqMw/AWzqUmaYFDNAuT2LM2lmtZRDybdfd5Y\n",
       "MFWgH6GXJYjHeJlGr7KXhPR1RVY71GS+31h3RkS4mA/U0r31Xpw1IZKg1YV6mn4qqHpS3FyjMAFV\n",
       "xej4uiZDaYRUCLT03nm+BLPevEsVzz26PMHyawf9tYlVKfoHlkyiua3TT86DGIeTSbQH865k2nuX\n",
       "lOzjW2J1yybFf1PJAPKgEBo+9b9aqzYfzNgfk+l4/fruY8xS2jNZ5zicdjI1/qZWcO8iwjR16RRj\n",
       "Qrn//PqEvYd4bQiZZa1sOwGWVlBgJYljDMeHD/cRUNYm3yqZA/uFCLz1AJo4m8uRPzUQjAC5NyUt\n",
       "DaiaPqLTYdcZbmlajaGZGoVM61C9mll/pr7sMu2BFvhbzOQQDxjb+nQ3CjrT2cjGhBlY+a7/BDeE\n",
       "vcvzOm1ewcPSN6GwQ5MSYR0Mqz7s4LasoxiWF70Ntt3VKbbAloeq4d4q4twCBlbUe2U4v99pOMBk\n",
       "Vs5YGMXcIv+2Q+9+3PD2leHwn4oSxvFwa8DzyIRMbMXshAEpnaNvszQm7P47hGokWZS/JL85vYaI\n",
       "0fqI0EBAjIgGGT9AgF7XUcKcW5ZBTtc7o7aURm+Yg0SwMH2leW0r0yJ3F9LGg1tIgvlySlw12OC4\n",
       "uyfdddW2Plh//GP5Kqrgym6X5FTQ40TqKJQj1ACtoJX7jZdnPcEkN4kaZueISXmy4kI7ZkBMdjsE\n",
       "xW1NleWtEWmbJicZInutpNFKjTuzOoX9W/RJCzbuBZMxwXJ6VXZYrZqfyiaGkm2CHF83fkQ1frxU\n",
       "8rY+m+mLMkWqJVq6QR9EbG9PiHXZHj+SwI1+6kX0UKpKhSrmR3PdMk4M3JmHtzOZj0rSMwYBKP3A\n",
       "qm8OMrmqoavBL+Qz3R99yvf4B4fi7vzkTeTuAkbT8LeFgTopYT3m+mZIrVPwdEBHYYFRN+ckpdim\n",
       "ycfAnlrj1zBxCC4DW1Kejm0bjy3KdKAMl6+ehxoz0d7xkVBJ1AsK3fKokrclufFVMblP76T5GIVV\n",
       "UwNRwEjv8cjbm8ZCKT9+4tB7qgcvUKG4cU0xJ2gaikVbIlOe5TUEODvdmY+H+Ya8axa9dO3zqFp3\n",
       "ZouBTXndCyJMxG19iyMIOvNX7Zag7S0C7nLT3hI1TCuwgdk39TDQ8OzbEIIFD3uwMx2h5UKy3lxn\n",
       "jCRV9FqLLnfKhKeZxVVC5TWWOsleYHuLzoMCerXRdym6Ns+K4ok1GIwaphwb6jKjxOgtFRXuXxQI\n",
       "vOSu+qU89uMohIOZRievYlubDSccT3zPK70bppkGr2gw/QLK5WlVSn1W9MkEo9LSQA8iDcdmyR1M\n",
       "k5WGoA6tsAn7KrQmP1fmQKOrMedLMJxlLM37uENsFxsIByg1s8fnAkLFonqKEhgv+ij4p8qoeqM5\n",
       "z5HyV5X/9++/82QrIPrE/o0mV9rMlR1AeWU5LB2Vjrc3vA9FlK87JpeTDWzvj22iVP2jiIbu8OLT\n",
       "G6pAq1xgbGSj2CQQZv4Py0nAtUHuzjtRu6jKv+n+7ZDTsS4cHC87R7wzZoiHo6Ec03hiO8st1eNN\n",
       "ZP0THmK3kgvEoz2qem/rsQO8g/vXa0tTL7vrssFqbcUdhFP5GXGHx7Sy7yXcZ3pMVfSqck0HALmF\n",
       "YwHJkvo2MLZ7YdV2OpdgNf3mqygBtb8fhZfW2KX3YcpSiueDGI2S14nQZnj5Tu0o3Hmasfz3PGcH\n",
       "xLCUBqL0HACFr4edE1D94QDkAT/SsowD2ZeyAAADAZEAAAdCQZohbEF//tqmWACl/vcIj/w34/AA\n",
       "OMUEfsNxsOFiSKr7GgCI8xNCqZBJ98oImsJ++fz152aVDAhC57NO551IdD/Ve67CMM0bOw+oPJaQ\n",
       "/2CXG2DkmVBRE092xvj5Wk3BhK3m1PNt+cVRyuWFmrKxwbHNE70ZVcFra4dr9wN/90TWljiT6/BO\n",
       "7PvJpAHNzjNTzfFWIyf8KyO588tTp/YmFAnonISwUcmU+/sUakyCRHi88TIW7gxGp7G1xP3OtBvr\n",
       "wPUjkgCzAasJ9NjLc2cFLPUunGJSHRieEuUCffeQPaDPFFqtGspRTJXQKa4EqKvLcXkrskkOyuJR\n",
       "s7q1bQOm2f4H5eFa6ITdS3M9f9hFuanCkJHWi2+XTM1WX0htZCMjtY35U4Wdkve46YNOIoakCvxa\n",
       "Cfyz7nALZrfKN1iEfVlMFPADyyoCVwJuAHEv5R850wi/GpyulzwkjpiVHJYti0OXyZGSNO+USZNM\n",
       "sYn519U3PWC5XTCs2XA+515bRrc9nCN5yGhbEt24yg1xlLuqykXkfYGrmuOOcpwGIiLpr6fO/eKx\n",
       "yIn7qP4Fp9Em9bJ8U6KHvEaseNsVrQWrlmq74pFr39ZauKUmk3JGeIUZENTxisy5TClGOWSIHmLG\n",
       "AnAxFQHSXDQJ7PV+c6O+rxAIAdxKJQ1Q1F3NvNrXu+igg+dauYdBzX+DhwR3MN2hmECHMYL0hbE6\n",
       "3Ovel1r91a73do47AnwEsNG3hRWDuV45GvjkiVqc5vjWgWnB+AkF712eaeU2Thot+rcijUyiy33M\n",
       "V8EUWvcfvSvlN+Ss8pDpPks9ulpCzSJGRU66haQ1PCZZ6DWQp0Ky6sMunkKpc8lloE1/S6eMceAC\n",
       "hTLYQiIOiX1gGXLHinaUMvWsVejOU1OqLH8AoCO5lQ4ZXpG00AeH9IBEmsX1ANAi4iwacVv7a4Qo\n",
       "oDd8Gj+Q9ZAFz76+A0P/+6QQJyaD8eaEj3kVTaPTkpUxw9/NCIub4cGHgtX8Z+7ULizE1OHs/rGg\n",
       "+J5L7f1W/NI0C9jNiOLro8OMSYXNYLO9YfotL7cUW7Kk03Js7ZFWRXkSYLc/gJ+M9RkLdd6xu1Mt\n",
       "irJirWHwWWMRIcnI+M9cFkI9JEiJvXc/exAZldHf3mzM/rU/Wlpk3ZdF8NGVvhDmApTm8mcIQgLu\n",
       "+BYi6QuCg9szSsDmNQw1rvdZT02wQeMu6STmlgQDWjWn/pRk3zl/dcoesa9S8ILXniP82r3+kEOm\n",
       "bM4EuNm0sqwCF4A/BJ2gNIuyay8x5RgrB93AJAFawTDJ1nGYKqh5ORpUa7BWUDen7dJ4sfvtIuL4\n",
       "JYnawEy/R5osNGKw7FvXEPvbMBqrIONyDIbs2SSBgFm58z6Sgt6WvZhURvErX5z1wpz9jMJPBNNj\n",
       "Um4cl7eb2IByZZ/MluzxbQ7UsPDfUWEzFtKrN8N/uvirZ41/uXkSzBjJfqzy6MoZ13evjNbrfCgC\n",
       "akFOKZZ7dZo2A9ieinZgQaEljRlwRT5q6d1NCCSCpcsHc/hRJWPRAhnmKvFMhXBvQLQBz0vI35mv\n",
       "vABsSMmD9DH56fJE0DfB8eycTGnTBeSO/wq0iGX1uu4O2VO/utcZ1FkK9vWG9f56B4McuNJvTkE5\n",
       "SoB15m90XSE0zd37SmD3ediiSwliaufuaJ3RAbCE3PGWmNMco6KP0qdWCa3rREpjbt5SdSpfujp2\n",
       "Mspt06SsV6GQdZk/9asY46B8dRZzM6dfhdGgin6e9LgmVs53hP97zCncuNNistOlIVpxT1kQ0uZH\n",
       "hpUA+SHYbIuf9XQMFAaYhdbhL1GHFU9QqpLsGnucXpdKCPG64le6NXsmAkh5U4ed/KQ5Ju94yOiJ\n",
       "dBftxGXmFxcdZka/I5+Ix4Gi22U0VbtIqNFw++3B274d+s4b2QiOyupsbuvQdEHJkrD3q0rteG/n\n",
       "KOkI5krzVCMFlEGJSRnVFwuFN6k9m//scCfn9GlGYP9S4K6/CeHmkmgtPWI4fKACKa+4F4GmujDv\n",
       "LjjQn2h0jenxyMDDk2qbXYiKdeVsafWqEQYEi6pHypGsA26/57B3u5t3XdcGLBPziS8q7QDdTwv+\n",
       "bKG70KSP67KFDWxOJh+lpqKDmfdS4KOpBng+wkuTS4eajt+iabVrclHBywJ6gFhGjasr0Rrocnus\n",
       "QBtYk7iv5FRMPyHGDZE/vPIP1KkhuzqS1rKY6mHNVUlIHIJxvFY6V6HROB/y+zChoVyNrQkjj8/3\n",
       "m93KqcoJvwkYyKfBMVNK4qTpmYzmsqW0EPjynveh0i5RLYzVMerkbrIRzNCMKRGIr1YGwbv0pU4d\n",
       "YnntgM3e63QEy7TF/n/8PkP/9GXhpWn211CRgDyXyrbIMOkKrBmtOWO3iy2n+8yhcjN2/i9ug+dI\n",
       "aenb6vo9QpyJXRtE16qIEzz32mnxZkCRUU2z3fDkRdoQNuzKxANn/72KG45w2Ic/8Jdp4S+z9u6/\n",
       "Uj/Ow6XzwsmDmXw2YAAABLJBmkI8IZMphBb//talUAChfvZrlRUIqUUmJ0vegAuk4G8KcKG0z/M7\n",
       "67Dlax1Yi8xNKqmzoHTM2uWCDSLxdRveovY6Qk/xxxIUQY+kN8l9AunQJdEddwoXf/uPi2R9FFe/\n",
       "0DR7HKYoiMFgRnX6ozi/CjataWh4g9Iu9iukblZU9UZsU3hzBueC0Eki6gijqYx6T+2SpcaFvf/N\n",
       "7jNKHZ9xiwyBf5RqFCRv9xnqc2f3t8jTDnPvP5R5bTwzZhebs05xdinpvitv5ccTsXrcV7K8KZY/\n",
       "XxplRqvtGWig8FWWgQk96ZkIhtvcjZk+vqb3O9Ld0H8P0+m2eVkjxo5JLn0+6QCTrQYpT8PbuQBg\n",
       "yVUz8KT0tVgUMwAd75IVj1m7v/QtUefCDy2+8Exiv7ADa/LIQ5pIBwSGEAANMmRMkoja7mOuNoVl\n",
       "auN524Cq+o1L7va0oVGJwyrxc84YiZONfwmlnxrdsa+GKftV2nONIZn0NwaeNaVrvAtg5B6NfaKD\n",
       "Knn/e1VrV41TKffeqVJl8mtA2BWbQmUBFl6iuGRu/432zla0aN5sFkrfGEWFI1prv7Mk09LqSwMl\n",
       "IhnNoLu725jUl7xUY8opEnsriDR0jT56kiHWJ3w5WOfspSbZeaERLFywgnQ8pA/ndAtlxWdqq+Tt\n",
       "XAAZjsHEgdWQnTsEpe6McWDfpPSsLN7z+SaHbwsKYcQ0GPzz9RsxJu/roSCtkJ4Nyhxd3qaMp/uo\n",
       "ku3ur/3Vfw5yTT0qiabHfC0ePsirzrnk1doLro5yCTs9BoF85RcEOiF7citpUVD3Ms4txj8i4W5e\n",
       "3h8UPjX3BKMXZ5JkpliRxn85vSIxrzoxNCbwz4jyZGk0XsXCje62wkHGSrGiMBahD4eaIOmDWoEP\n",
       "7acQMwc/c94Y5U52Ug0Amd0ttw+ODqQ77gQtwKgV25F17wmV8uUTIP9CZbh1l7I/LJKTXJawjch1\n",
       "pu9puBfVHFoJCkLwkSmdV9q7nA2gNU3/gACOue/vSRrPgeV511xSK4PCN7dgoVeJmsTyVxwgSvsU\n",
       "Y7BUHolDGVAETbUD+wo+KtB4bh5qB4exdaJOo0K+S8zPBfW9INEKTVUCJWwuZ5smIzXr608I4/YH\n",
       "7uJU6J5fMq0PII2qVSH+r2jdAVa0C/ZuYTOH7rX1W2z7f5e5VEFo2cmu5PpsH+hCrZsFiKaXqv2K\n",
       "hb7uJlnXTk7Szvn35PuNMrUKkGx7PsNvHAGUSzseBXvklBorK5yYn0mdugUcd1QKRbyodQbPmt6h\n",
       "ON1sWP6SS4xjHdwd/rRn67zUS4yZed1dl7U3Sgiq7+Jfaeej6FV3ELKM5L/LysK6Vva2qduutPS3\n",
       "CqfyYn/0FklDPNcbc5X58BPyH0FRziugksxLCLxQgZ12hCC9y3AGEYMVHfUy52PIFyl2L+BU46Wt\n",
       "T9StBGz6ZeQlnE6F2gsNxzIDnHKGLI7SjjWQ21ex3WWs9E84RbjH13rbX013G9rcFDOeWHrLjY2b\n",
       "zU1qt/NsHzdmVPOabOfTQWcp+khJ8aln0wiHQaz6iWhOeSnlQLFoJic8LG3WpWz5Mv/B2LGQfZKu\n",
       "C/RDSXWxjzpJn4xPEUeorBzjvAbzgQAABKZBmmNJ4Q8mUwIK//7WpVAAlF2v/356gaABEAT/kEYH\n",
       "h/5dpvJXUQHHGSPA9R6oMYQ1KU6JW1G5z3mxvsuIKKvwdyX+eOEjl9p1KFEed3ALhCD/aG8DbYKn\n",
       "EJs84a5BZ+DA/2Yi/BVCaOFKBuZ6dIfjlSg0ecsbNfZD7CBL16g/JxVJJH/rX7if/cBGRdsYJbkl\n",
       "8Cv+wl+6NyL40Olm/emCsc7nTzlCaegVgiCSFeLMwBnTt7nImO5Wtid3SLKCUWrgTWCqYoX0Aot6\n",
       "p8xEed6y145j31ZDCgQV/7Ur8vXWJb3EDa0EUelfeKemPP+R/Sh7sALe8aNv82n9hYfHkdNh901n\n",
       "czOB1ya4qtyXdjLw/SID8o4A0VF7YQ8rO3O+cwweAMj0EiV4I/jWinSIMziBOgMgdr0dy2ubvA/H\n",
       "slgSnQx9Zslx7ecblY/LvMYHa1QKTKA1z+sIWZrmwZLl/1AI6dKn3XUVvHOdd/ih+B3RmoaefW2h\n",
       "4kLO7lb9NIJccmo9CUQDYipZP8U0xUhqG45Y4WflZeI1F5yqxDA9q3dYlwecsJwuioAxA/LaeN7P\n",
       "e87zLFgCtIWStsCUFMEzpkoXoaoi1sPTU7CDyz0WgbJICluMMJ4WmUmEljSuTAiUcS5ONYyBRfjU\n",
       "EmM7gLLrwQue7EXNQgeF9vSu8pUJafcJpjOU+mVeH0+RFxaBY2pnFoJNfd+oD9YY6JIOpJd1hp3i\n",
       "+8/wT4vQ4rPP0Fz/Z02n0U4h90te2l5DJFBBwL5c93BvFfXd/hDmjpOKekBeoqWp5EOt3mm3kCcV\n",
       "xHSC25MhfMZOUVgz+Fpq+RqVZIbxf9pMnfHiznue6NGJEbMl1f4jWpRhRMOzgjwEtqe+HMlKgBEM\n",
       "wK1MnJx6tG2zMtXr1L4CZ7gQayWGptS0lcjcRj7aeMWDB7ffE7A2x8d8lPZfczkI3GHC0hXGxDFn\n",
       "e2EpRCrzeM+y8ed8IoI8skNUMS29LhINrzwn5balbcCZWNcUgVCMhe6Kc2kY3AzDeDsxPle1VIZL\n",
       "2yJFrlHWjlxYR8QpMipY2KVIPdnEQPm4+XsosNN9g2Navm2z4JIUeeDb9csHhO7qMqbGDyETPCJw\n",
       "hNLXtFVFnk17EJ6yEdAhEBVyxDHLMwLAAQb+swz3xlYAagIwKeyh9DDbPeBpDp+IgNkctQTuvW9s\n",
       "t49t/88mG2nr4uSPjvfPNWNDniqaU0/EKZVMnfvStxOG07x89MBWWEcLzRDNdiKNdm6OMg1/oMc8\n",
       "Ge0AbGggtTAqkTNZo3rxwjzzKA/JRk/rtAsYiRsWiLKdgzHKPiwpUDR/GJ9NBsrmU95cDoxpk+9I\n",
       "9coSuI5DLkXBa6NFSVJJ0X94sUwHPmYy9LfuTmxUcdmwqnXWOGVZt6la9sGjKiXo/q7mJvojW87i\n",
       "PfniGPM3TLX71ALCWSrV+vWtOVkM+eDqalQAws1VzdAPkGR/1RM4XAjktMozUzYiAD6sVUqVuVFt\n",
       "EE2uV78ryYM1C/NumpR48hdnlcjOHjh++RHuKFiqqJbCHfOpDctMhwTCIIZEeoRktwOR62zhUzRG\n",
       "sX4TjIRj2MH4T46RelOFyzlcagAAA0htb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAfQAAB\n",
       "AAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAA\n",
       "AAAAAAAAAAAAAAAAAAAAAAAAAAACAAACcnRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAA\n",
       "AAAfQAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAB\n",
       "aAAAAWgAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAH0AAAQAAAAEAAAAAAeptZGlhAAAAIG1k\n",
       "aGQAAAAAAAAAAAAAAAAAAEAAAAIAAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAA\n",
       "AFZpZGVvSGFuZGxlcgAAAAGVbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJl\n",
       "ZgAAAAAAAAABAAAADHVybCAAAAABAAABVXN0YmwAAAC1c3RzZAAAAAAAAAABAAAApWF2YzEAAAAA\n",
       "AAAAAQAAAAAAAAAAAAAAAAAAAAABaAFoAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAA\n",
       "AAAAAAAAAAAAAAAAAAAY//8AAAAzYXZjQwFkABX/4QAaZ2QAFazZQXC/llhAAAADAIAAAAMAg8WL\n",
       "ZYABAAZo6+PLIsAAAAAcdXVpZGtoQPJfJE/FujmlG88DI/MAAAAAAAAAGHN0dHMAAAAAAAAAAQAA\n",
       "AAQAAIAAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAAYY3R0cwAAAAAAAAABAAAABAABAAAAAAAcc3Rz\n",
       "YwAAAAAAAAABAAAAAQAAAAQAAAABAAAAJHN0c3oAAAAAAAAAAAAAAAQAAA/8AAAHRgAABLYAAASq\n",
       "AAAAFHN0Y28AAAAAAAAAAQAAACwAAABidWR0YQAAAFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABt\n",
       "ZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU3Ljcx\n",
       "LjEwMA==\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<matplotlib.animation.FuncAnimation at 0x11a1eb4e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.reshape(img,[4,28,28])\n",
    "print(\"Labels: {}, {}, {}, {}\".format(label[0],label[1],label[2],label[3]))\n",
    "plot_image_batch(img,label) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training batches are good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
