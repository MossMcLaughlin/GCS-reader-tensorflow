{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BUCKET = 'gs://kaggle-tsa-ml'\n",
    "DAT_BUCKET = BUCKET + '/data/'\n",
    "DAT_EXAMPLE = DAT_BUCKET + 'fcf366a672d2809b0d158180ecb4dd5c.aps'\n",
    "\n",
    "IMAGE_SHAPE = [512,660,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_APS(filename_queue):\n",
    "    class APSrecord(object):\n",
    "        pass\n",
    "    result = APSrecord()\n",
    "\n",
    "    result.height = IMAGE_SHAPE[0]\n",
    "    result.width = IMAGE_SHAPE[1]\n",
    "    result.depth = IMAGE_SHAPE[2]\n",
    "    image_bytes = result.height * result.width * result.depth\n",
    "    label_bytes = 512 \n",
    "    record_bytes = image_bytes + label_bytes\n",
    "    \n",
    "    reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n",
    "    result.key, value = reader.read(filename_queue)\n",
    "\n",
    "    # Convert from a string to a vector of uint16 that is record_bytes long.\n",
    "    record_bytes = tf.decode_raw(value, tf.int16)\n",
    "\n",
    "    # The first bytes represent the label, which we convert from uint16->int32.\n",
    "    result.label = tf.cast(\n",
    "        tf.strided_slice(record_bytes, [0], [label_bytes]), tf.int32)\n",
    "\n",
    "    # The remaining bytes after the label represent the image, which we reshape\n",
    "    # from [depth * height * width] to [depth, height, width].\n",
    "    depth_major = tf.reshape(\n",
    "        tf.strided_slice(record_bytes, [label_bytes],\n",
    "                         [label_bytes + image_bytes]),\n",
    "        [result.depth, result.height, result.width])\n",
    "    # Convert from [depth, height, width] to [height, width, depth].\n",
    "    result.uint8image = tf.transpose(depth_major, [1, 2, 0])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _generate_image_and_label_batch(image, label,\n",
    "                                    batch_size, shuffle,min_queue_examples=10):\n",
    "    \"\"\"Construct a queued batch of images and labels.\n",
    "    Args:\n",
    "      image: 3-D Tensor of [height, width, 3] of type.float32.\n",
    "      label: 1-D Tensor of type.int32\n",
    "      min_queue_examples: int32, minimum number of samples to retain\n",
    "        in the queue that provides of batches of examples.\n",
    "      batch_size: Number of images per batch.\n",
    "      shuffle: boolean indicating whether to use a shuffling queue.\n",
    "    Returns:\n",
    "      images: Images. 4D tensor of [batch_size, height, width, 3] size.\n",
    "      labels: Labels. 1D tensor of [batch_size] size.\n",
    "    \"\"\"\n",
    "  # Create a queue that shuffles the examples, and then\n",
    "  # read 'batch_size' images + labels from the example queue.\n",
    "    num_preprocess_threads = 16\n",
    "    if shuffle:\n",
    "        images, label_batch = tf.train.shuffle_batch(\n",
    "          [image, label],\n",
    "          batch_size=batch_size,\n",
    "          num_threads=num_preprocess_threads,\n",
    "          capacity=min_queue_examples + 3 * batch_size,\n",
    "          min_after_dequeue=min_queue_examples)\n",
    "    else:\n",
    "        images, label_batch = tf.train.batch(\n",
    "          [image, label],\n",
    "          batch_size=batch_size,\n",
    "          num_threads=num_preprocess_threads,\n",
    "          capacity=min_queue_examples + 3 * batch_size)\n",
    "\n",
    "    # Display the training images in the visualizer.\n",
    "    tf.summary.image('images', images)\n",
    "\n",
    "    return images, tf.reshape(label_batch, [batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gen_inputs(file_list,batch_size):\n",
    "    '''\n",
    "    Reads bianary files from GCS bucket \n",
    "    Input: file_list - File containing list of filenames to be read from GCS bucket.\n",
    "           batch_size - Size of training data batches.\n",
    "    \n",
    "    Output: Batch of tensors for training.\n",
    "            Batch of labels for training.\n",
    "    '''\n",
    "    # Read list of filenames\n",
    "    with open(file_list) as fns:\n",
    "        # Remove newline character form filenames \n",
    "        files = [item[:-1] for item in fns]\n",
    "        #test with 5 file\n",
    "        files = files[:8]\n",
    "    filename_queue = tf.train.string_input_producer(files)\n",
    "    \n",
    "    read_input = read_APS(filename_queue)\n",
    "    reshaped_image = tf.cast(read_input.uint8image, tf.float32)\n",
    "    read_input.label.set_shape([1])\n",
    "    \n",
    "    ###   Simple Image pre-processing   ###\n",
    "    '''\n",
    "    height = IMAGE_SHAPE[0]\n",
    "    width = IMAGE_SHAPE[1]\n",
    "    \n",
    "    \n",
    "    # Here we can crop the image if desired.\n",
    "    #resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,height, width)\n",
    "\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    float_image = tf.image.per_image_standardization(resized_image)\n",
    "\n",
    "    # Set the shapes of tensors.\n",
    "    float_image.set_shape([height, width, 3])\n",
    "    read_input.label.set_shape([1])\n",
    "    return _generate_image_and_label_batch(float_image, read_input.label,\n",
    "                                         min_queue_examples, batch_size,\n",
    "                                         shuffle=False)\n",
    "    '''\n",
    "    return _generate_image_and_label_batch(\n",
    "        reshaped_image, read_input.label, batch_size, shuffle=False)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
